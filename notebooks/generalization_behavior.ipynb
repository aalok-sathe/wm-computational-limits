{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generalization behavior of networks\n",
    "here we evaluate (behaviorally) several networks on various datasets of different properties\n",
    "and try to understand what training exposure leads to generalizability on what other kinds\n",
    "of data distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import typing\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import workingmem\n",
    "import workingmem.model\n",
    "from workingmem.task.SIR import SIRDataset, SIRConfig, SIRTokenizer\n",
    "\n",
    "from best_worst_models import best_worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../configs/ref_n_back.yaml_25-11-19_sweep_dict.yaml\", \"+r\") as f:\n",
    "with open(\"../configs/ref_n_back.yaml_25-11-30_sweep_dict.yaml\", \"+r\") as f:\n",
    "    sweep_data = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, record in enumerate(sweep_data):\n",
    "    sweep_id, td_prob, role_n_congruence = (\n",
    "        record[\"sweep_id\"],\n",
    "        record[\"dataset.td_prob\"],\n",
    "        record[\"dataset.role_n_congruence\"],\n",
    "    )\n",
    "\n",
    "    print(f\"{sweep_id=}, {td_prob=}, {role_n_congruence=}\")\n",
    "    model_ckpts = Path(f\"../model_checkpoints/{sweep_id}/\").resolve()\n",
    "    # count the number of checkpoints in the checkpoint directory\n",
    "    num_models = len(list(model_ckpts.glob(\"*\")))\n",
    "    all_model_paths = [*best_worst(model_ckpts, num_models, verbose=True)][:num_models]\n",
    "    models[sweep_id] = all_model_paths\n",
    "    print()\n",
    "\n",
    "sweep_data = pd.DataFrame(sweep_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to load two datasets corresponding to\n",
    "# - role_n_congruence = 0\n",
    "# - td_prob = {0, 1}\n",
    "datasets = {}\n",
    "for td_prob in (0, 1):\n",
    "    for role_n_congruence in (0,):\n",
    "        # select the row where `td_prob` and `role_n_congruence` match the desired values\n",
    "        row = sweep_data[\n",
    "            (sweep_data[\"dataset.td_prob\"] == td_prob)\n",
    "            & (sweep_data[\"dataset.role_n_congruence\"] == role_n_congruence)\n",
    "        ].iloc[0]\n",
    "        # get the corresponding `sweep_id`\n",
    "        sweep_id = row[\"sweep_id\"]\n",
    "        # pick any model config for this sweep from the list of models\n",
    "        model_conf = models[sweep_id][0]\n",
    "        history_path = model_conf.from_pretrained / \"history.yaml\"\n",
    "        history = yaml.safe_load(history_path.read_text())\n",
    "        # look into its history for dataset path and load the dataset\n",
    "        this_dataset = SIRDataset.from_path(\n",
    "            history[-1][\"dataset_path\"], split=\"val\", generate=False\n",
    "        )\n",
    "        # record the dataset in our dictionary\n",
    "        datasets[td_prob, role_n_congruence] = this_dataset\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    datasets[0, 0].tokenizer.encode(\"St reg_5 item_1\").ids,\n",
    "    datasets[1, 0].tokenizer.encode(\"St reg_5 item_1\").ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for _, row in tqdm([*sweep_data.iterrows()]):\n",
    "    src_td_prob = row[\"dataset.td_prob\"]\n",
    "    src_role_n_congruence = row[\"dataset.role_n_congruence\"]\n",
    "    # if src_td_prob in (0, 1) and src_role_n_congruence == 0:\n",
    "    #     continue  # NOTE temporary exclusion\n",
    "    sweep_id = row[\"sweep_id\"]\n",
    "    for model_conf in models[sweep_id]:\n",
    "        print(model_conf)\n",
    "        # load model\n",
    "        wm_model = workingmem.model.ModelWrapper(model_conf)\n",
    "        # evaluate this model on all datasets in `datasets`\n",
    "        for (tgt_td_prob, tgt_role_n_congruence), dataset in datasets.items():\n",
    "            out = wm_model.test(dataset=dataset)\n",
    "            loss, acc = out[\"loss\"], out[\"acc\"]\n",
    "            records += [\n",
    "                {\n",
    "                    \"src_td_prob\": src_td_prob,\n",
    "                    \"src_role_n_congruence\": src_role_n_congruence,\n",
    "                    \"tgt_td_prob\": tgt_td_prob,\n",
    "                    \"tgt_role_n_congruence\": tgt_role_n_congruence,\n",
    "                    \"loss\": loss,\n",
    "                    \"acc\": acc,\n",
    "                    \"sweep_id\": sweep_id,\n",
    "                    \"model\": model_conf.from_pretrained.stem,\n",
    "                }\n",
    "            ]\n",
    "        # break  # break if top-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(records).to_csv(\n",
    "    \"td_role_cong_generalization_ignore_aware_20251203_all.csv\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
